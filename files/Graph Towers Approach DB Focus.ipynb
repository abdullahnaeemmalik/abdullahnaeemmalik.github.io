{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bcf327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sqlite3\n",
    "\n",
    "import cProfile\n",
    "import dgl\n",
    "import torch\n",
    "from line_profiler import LineProfiler\n",
    "from tqdm import tqdm\n",
    "from torch.sparse import *\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "os.environ['DGLBACKEND'] = 'pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ecdcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unpacker():\n",
    "    \"\"\"input of quotiented_simplices is a dictionary with keys = (dimension, simplex_id, globe_id)\n",
    "    and values = [v_0,v_1,...,v_n]. Node mapping is also a dictionary with keys = nodes\n",
    "    and values = a list of pre-images. Such a list could be a singleton, but never empty\n",
    "    because the quotient map is a function in the math sense. The other inputs concern the graph downstairs (range graph)\n",
    "    and the graph upstairs (domain graph).\n",
    "    \n",
    "    This function pushes simplices from downstairs to upstairs, and does this by looking at degenerate simplice downstairs,\n",
    "    then finds possible preimages for them upstairs, and does so inductively. The highest dimension for which we need\n",
    "    to look for a simplex is dictated by the graph upstairs, and is decided by self.local_max_dim.\n",
    "    \n",
    "    Finally, the simplex_max_index takes the index from the previous section finder, and increments it for simplices\n",
    "    that are found later.\"\"\"\n",
    "    \n",
    "    def __init__(self, domain_graph,node_mapping,range_graph_edges,\n",
    "                 deg_edges,quotiented_simplices,simplex_max_index,globe_number,domain_graph_edges):\n",
    "        \n",
    "        assert isinstance(domain_graph, dgl.DGLHeteroGraph), \\\n",
    "        'Keyword argument \\\"domain_graph\\\" must be a dgl.DGLHeteroGraph.'\n",
    "        assert isinstance(quotiented_simplices, dict), \\\n",
    "        'Keyword argument \\\"edges_list\\\" must be a dictionary.'\n",
    "        assert isinstance(node_mapping, dict), \\\n",
    "        'Keyword argument \\\"node_mapping\\\" must be a dictionary.'\n",
    "        assert isinstance(deg_edges, list), \\\n",
    "        'Keyword argument \\\"deg_edges\\\" must be a dictionary.'\n",
    "\n",
    "        self.simplex_max_index     = simplex_max_index\n",
    "        self.domain_graph          = domain_graph\n",
    "        self.node_mapping          = node_mapping\n",
    "        self.deg_edges             = deg_edges\n",
    "        self.range_graph_edges     = range_graph_edges\n",
    "        self.quotiented_simplices  = quotiented_simplices\n",
    "        self.lifted_simplices      = dict()\n",
    "        self.globe_number          = globe_number\n",
    "        number_of_nodes            = len(torch.unique(torch.cat(self.domain_graph.edges())))\n",
    "        in_degrees                 = self.domain_graph.in_degrees()\n",
    "        out_degrees                = self.domain_graph.out_degrees()\n",
    "        possible_max1              = min(int(torch.max(in_degrees)), number_of_nodes-1)\n",
    "        possible_max2              = min(int(torch.max(out_degrees)), number_of_nodes-1)\n",
    "        self.local_max_dim         = max(possible_max1,possible_max2)\n",
    "        self.domain_graph_edges    = domain_graph_edges\n",
    "        self.preimages_collection  = list()\n",
    "        self.injective_nodes       = list()\n",
    "        self.non_injective_nodes   = list()\n",
    "        self.truquotiented_simpl   = copy.deepcopy(quotiented_simplices)\n",
    "        self.new_simplices         = list()\n",
    "        self.all_range_g_edges     = self.range_graph_edges + self.deg_edges\n",
    "        \n",
    "        # Seperate the nodes that are mapped injectively\n",
    "        for node, preimages in self.node_mapping.items():\n",
    "            if len(preimages) == 1:\n",
    "                self.injective_nodes = self.injective_nodes + [node]\n",
    "            else:\n",
    "                self.non_injective_nodes = self.non_injective_nodes + [node]\n",
    "        \n",
    "        index = 0\n",
    "        _nodes = set(self.non_injective_nodes)\n",
    "        for key, quotiented_simplex in self.quotiented_simplices.items():\n",
    "            if key[0] > 1:\n",
    "                common_elements = _nodes.intersection(set(quotiented_simplex))\n",
    "                if len(common_elements) == 0:\n",
    "                    # If the simplex downstairs is the same as the simplex upstairs, then add it to the dictionary\n",
    "                    key_lifted = (len(quotiented_simplex)-1, self.simplex_max_index+index, self.globe_number)\n",
    "                    self.lifted_simplices.update({key_lifted:quotiented_simplex})\n",
    "                    #T he simplex found is not a degenerate simplex upstairs, so we don't need to find its sections.\n",
    "                    del self.truquotiented_simpl[key]\n",
    "                    index = index + 1\n",
    "                else:\n",
    "                    # Work out the simplices upstairs that have images of the same dimension downstairs\n",
    "                    degeneracies = self.generate_youngs_list(quotiented_simplex)\n",
    "                    for degeneracy in degeneracies:\n",
    "                        if self.simplex_verifier(degeneracy):\n",
    "                            key_lift = (len(degeneracy)-1, self.simplex_max_index+index, self.globe_number)\n",
    "                            self.lifted_simplices.update({key_lift:degeneracy})\n",
    "                            index = index + 1\n",
    "        self.simplex_max_index = self.simplex_max_index + index\n",
    "        self.new_simplices = list(self.truquotiented_simpl.values()) + self.range_graph_edges\n",
    "        \n",
    "    def inductive_connecting(self):          \n",
    "        new_zero_skeleta = self.new_simplices\n",
    "        self.images = []\n",
    "        for src in self.non_injective_nodes:\n",
    "            for zero_skel in new_zero_skeleta:\n",
    "                if len(zero_skel) > self.local_max_dim:\n",
    "                    continue\n",
    "                if zero_skel.count(src) >= len(self.node_mapping[src]):\n",
    "                    continue\n",
    "                if src not in zero_skel:\n",
    "                    continue\n",
    "                edge_present_query1 = True\n",
    "                edge_present_query2 = True\n",
    "                for dst in zero_skel:\n",
    "                    if edge_present_query1:\n",
    "                        if [src, dst] in self.all_range_g_edges:\n",
    "                            index_to_insert = zero_skel.index(src)\n",
    "                            if zero_skel[:index_to_insert]+[src]+zero_skel[index_to_insert:] not in self.images:\n",
    "                                self.images.append(zero_skel[:index_to_insert]+[src]+zero_skel[index_to_insert:])\n",
    "                        if [dst, src] in self.all_range_g_edges:\n",
    "                            index_to_insert = zero_skel.index(dst)\n",
    "                            if zero_skel[:index_to_insert-1]+[src]+zero_skel[index_to_insert-1:] not in self.images:\n",
    "                                self.images.append(zero_skel[:index_to_insert-1]+[src]+zero_skel[index_to_insert-1:])\n",
    "       \n",
    "        if len(self.images) == 0:\n",
    "            # No more images are found, so we can stop the induction process\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            self.preimages_collection = []\n",
    "            self.preimages_collection_id = dict()\n",
    "            for image in self.images:\n",
    "                preimages = self.generate_youngs_list(image)\n",
    "                for preimage in preimages:\n",
    "                    self.preimages_collection_id.update({id(preimage):image})\n",
    "                self.preimages_collection = self.preimages_collection + preimages\n",
    "            self.add_simplices_to_dict()\n",
    "            self.new_simplices = [list(image) for image in self.simplices_to_extend]\n",
    "            self.inductive_connecting()\n",
    "    \n",
    "    def generate_youngs_list(self, simplex):\n",
    "        \"\"\"Takes as input the image of a quotiented simplex spits out all possible simplices in the pre-image\"\"\"\n",
    "        \n",
    "        indices = [range(len(self.node_mapping[key])) for key in simplex]\n",
    "        combinations = itertools.product(*indices)\n",
    "        result_lists = []\n",
    "        for combo in combinations:\n",
    "            alternative_list = [self.node_mapping[simplex[0]][combo[0]]]\n",
    "            for i in range(1, len(simplex)):\n",
    "                to_add = True\n",
    "                p_node = self.node_mapping[simplex[i-1]][combo[i-1]]\n",
    "                c_node = self.node_mapping[simplex[i]][combo[i]]\n",
    "                if (p_node,c_node) in self.domain_graph_edges:\n",
    "                    if c_node not in alternative_list: \n",
    "                        alternative_list.append(self.node_mapping[simplex[i]][combo[i]])\n",
    "                    else:\n",
    "                        to_add = False\n",
    "                        break\n",
    "                else:\n",
    "                    to_add = False\n",
    "                    break\n",
    "            if to_add:\n",
    "                if alternative_list not in result_lists:\n",
    "                    result_lists.append(alternative_list)\n",
    "        return result_lists\n",
    "\n",
    "    def simplex_verifier(self, simplex):\n",
    "        \"\"\"This function takes input a k-tuple [v_1,v_2,...,v_k] for k>1 and a graph G\n",
    "        and verifies if it a simplex of G. This is done by simply checking if there is \n",
    "        an edge between v_i and v_j for i<j\"\"\"\n",
    "    \n",
    "        is_simplex = False\n",
    "        simplex_reduced = copy.deepcopy(simplex)\n",
    "        \n",
    "        for i in simplex:\n",
    "            simplex_reduced.pop(0)\n",
    "            for j in simplex_reduced:\n",
    "                if (i, j) in self.domain_graph_edges:\n",
    "                    continue\n",
    "                else:\n",
    "                    # The input is not a simplex, so we can stop our check.\n",
    "                    return is_simplex\n",
    "        return True\n",
    "    \n",
    "    def add_simplices_to_dict(self):\n",
    "        index = 0\n",
    "        self.simplices_to_extend = set()\n",
    "\n",
    "        for preimage in self.preimages_collection:\n",
    "            if self.simplex_verifier(preimage):\n",
    "                key = (len(preimage) - 1, self.simplex_max_index + index, self.globe_number)\n",
    "                self.lifted_simplices.update({key: preimage})\n",
    "                index += 1\n",
    "                temp_dict = {tuple(self.preimages_collection_id[id(preimage)])}\n",
    "                self.simplices_to_extend = self.simplices_to_extend.union(temp_dict)\n",
    "    \n",
    "    def simplex_breaker(self,simplex):\n",
    "        \"\"\"This function takes a simplex and returns all the edges within it. I abondoned the plan to use it.\"\"\"\n",
    "        edges = list()\n",
    "        for i in range(len(simplex)):\n",
    "            for j in range(i + 1, len(simplex)):\n",
    "                x = lst[i]\n",
    "                y = lst[j]\n",
    "                edges = edges + [[x,y]]\n",
    "        return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf854178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_to_identify(graph):\n",
    "    \"\"\"Constructing the Hadamard product here to find the list of edges to contract.\n",
    "    All the edges that are parts of a 2-simplex are identified in this function\n",
    "    as indices of the Hadamard product. Moreover, other edges that are not part of the Hadamard\n",
    "    product, but are part of the transitive closure of existing edges are also identified.\n",
    "    These are the edges that form a complete 2-simplex.\"\"\"\n",
    "\n",
    "    assert isinstance(graph, dgl.DGLHeteroGraph), \\\n",
    "        'Keyword argument \\\"graph\\\" of create_hadamard must be a dgl.DGLHeteroGraph.'\n",
    "    \n",
    "    # First, we remove all diag entries from adj matrix A by removing all self-loops\n",
    "    loopless = dgl.transforms.RemoveSelfLoop()\n",
    "    graph = loopless(graph)\n",
    "    \n",
    "    # Then we remove all diagonals from A^2 and convert the matrix to one with binary entries\n",
    "    adj_squared = torch.sparse.mm(graph.adj_external(),graph.adj_external())\n",
    "    diagonal_mask = (adj_squared._indices()[0] == adj_squared._indices()[1])\n",
    "    off_diagonal_mask = ~diagonal_mask\n",
    "    adj_squared._values()[off_diagonal_mask] = 1.0\n",
    "    new_indices = adj_squared._indices()[:, off_diagonal_mask]\n",
    "    new_values = adj_squared._values()[off_diagonal_mask]\n",
    "    new_size = adj_squared.size()\n",
    "    squared_no_diag_binary = torch.sparse_coo_tensor(indices=new_indices, \n",
    "                                                    values=new_values, size=new_size)\n",
    "    # The Hadamard product is sparse, but keeps track of entries that are zero.\n",
    "    false_hadamard_product = graph.adj_external() * squared_no_diag_binary\n",
    "    \n",
    "    # We, therefore need to remove those entries.\n",
    "    false_hadamard_product = false_hadamard_product.coalesce()\n",
    "    non_zero_mask = false_hadamard_product._values().nonzero().squeeze()\n",
    "    non_zero_values = false_hadamard_product._values()[non_zero_mask]\n",
    "    non_zero_indices = false_hadamard_product.indices()[:, non_zero_mask]\n",
    "    if non_zero_indices.dim() == 1:\n",
    "        non_zero_indices = non_zero_indices.unsqueeze(0)\n",
    "        non_zero_indices = non_zero_indices.view(2, -1)\n",
    "    hadamard_product = torch.sparse_coo_tensor(indices=non_zero_indices,\n",
    "                                               values=non_zero_values,\n",
    "                                               size=false_hadamard_product.size())\n",
    "    \n",
    "    # The following loop finds all edges that are part of a simplex need to be collapsed.\n",
    "    row_indices, col_indices = hadamard_product._indices()\n",
    "    extra_edges = list()\n",
    "    \n",
    "    for i,j in zip(row_indices,col_indices):\n",
    "        out_nodes = set([int(v) for v in list(graph.successors(i))])\n",
    "        in_nodes = set([int(v) for v in list(graph.predecessors(j))])\n",
    "        # These are the elements in the (reverse?) transitive closure of (i,j).\n",
    "        intersection = set.intersection(out_nodes,in_nodes)\n",
    "        for k in intersection:\n",
    "            extra_edges = extra_edges + [(int(i),int(k))] + [(int(k),int(j))]\n",
    "    return hadamard_product, extra_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c32d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class graph_towers():\n",
    "    src=list()\n",
    "    dst=list()\n",
    "    empty_graph = dgl.heterograph({('node', 'to', 'node'): (src, dst)})\n",
    "    ratio = 0.0\n",
    "    bottom_level = 0\n",
    "    \n",
    "    assert isinstance(empty_graph, dgl.DGLHeteroGraph), \\\n",
    "        'Keyword argument \\\"graph\\\" of graph_towers\\'s init method must be a dgl.DGLHeteroGraph.'\n",
    "    assert isinstance(ratio, float), \\\n",
    "        'Keyword argument \\\"ratio\\\" of graph_towers\\'s init method must be a float.'\n",
    "    assert ratio<=1 and ratio>=0, \\\n",
    "        'Keyword argument \\\"ratio\\\" of graph_towers\\'s init method must be between 0 and 1.'\n",
    "    assert isinstance(bottom_level, int), \\\n",
    "        'Keyword argument \\\"bottom_level\\\" of graph_towers\\'s init method must be an integer.'\n",
    "\n",
    "    def __init__(self, file_path, ratio, database_name, max_dimension, graph=empty_graph,\n",
    "                 bottom_level=bottom_level):\n",
    "        \n",
    "        self.seed_graph        = graph\n",
    "        self.srcs_and_dsts     = self.seed_graph.edges()   \n",
    "        self.file_path         = file_path        \n",
    "        self.ratio             = ratio\n",
    "        self.updated_graph     = dgl.heterograph({('node', 'to', 'node'): ([], [])})\n",
    "        self.bottom_level      = bottom_level\n",
    "        self.database_name     = database_name\n",
    "        self.maximum_dimension = max_dimension\n",
    "        self.connection        = None\n",
    "        self.cursor            = None\n",
    "        self.number_of_nodes   = len(self.seed_graph.nodes())\n",
    "        self.number_of_edges   = len(self.seed_graph.edges()[0])\n",
    "        self.selected_edges    = None\n",
    "        self.quotient_number   = 0\n",
    "        self.simplex_id        = 0\n",
    "        \n",
    "        # Find list of edges that will be used to create a quotient graph\n",
    "        self.hadamard_product, self.extra_edges  = edges_to_identify(self.seed_graph)\n",
    "        rows, columns = self.hadamard_product._indices()\n",
    "        self.edges_to_collapse_as_pairs = torch.cat(\n",
    "            (torch.transpose(self.hadamard_product._indices(),0,1)\n",
    "             ,torch.tensor(self.extra_edges)),dim=0)\n",
    "        # Some edges from the 'extra_edges' and those given by the Hadamard product\n",
    "        # are duplicated. We need to combine these in one variable.\n",
    "        self.edges_to_collapse_as_pairs = torch.unique(self.edges_to_collapse_as_pairs, dim=0)\n",
    "        self.all_nodes_to_identify  = torch.cat((rows,columns),dim=0).unique()\n",
    "        self._equivalenceclasses    = dict()\n",
    "        self.appendage_index        = len(self.seed_graph.nodes())\n",
    "        self.edge_index             = 0        \n",
    "        edge_pairs                  = torch.stack(self.seed_graph.edges(), dim = 1).int()\n",
    "        self.all_edges_as_pairs     = edge_pairs\n",
    "        self.edges_carry_fwd        = list()\n",
    "        self.edges_never_contracted = None\n",
    "        self.simplex_id             = 0\n",
    "        self._all_sets_with_indices = dict()\n",
    "        \n",
    "        # Find all node classes to yield maximum class size.\n",
    "        self._globes = {element:partition for partition in relation(\n",
    "            self.edges_to_collapse_as_pairs) for element in partition}\n",
    "        index = 0\n",
    "        for key in self._globes.keys():\n",
    "            key_check = self._all_sets_with_indices.get(id(self._globes[key]),[])\n",
    "            if key_check == []:\n",
    "                self._all_sets_with_indices.update({id(self._globes[key]):(self._globes[key],index)})\n",
    "                index = index + 1\n",
    "        self.max_globe_index = index-1\n",
    "        index = None\n",
    "        self.maximum_class_size = max((len(set_value) for set_value in self._globes.values()), default=0)\n",
    "        self.loop_indicator     = torch.eq(self.srcs_and_dsts[0],self.srcs_and_dsts[1])\n",
    "        self.existing_loops     = (self.seed_graph.edges()[0][self.loop_indicator],\n",
    "                                   self.seed_graph.edges()[1][self.loop_indicator])\n",
    "        self.existing_loops     = torch.stack(self.existing_loops, dim = 1).int()\n",
    "        \n",
    "        # Finds globally highest dimension of simplices in the graph\n",
    "        self.in_degrees  = self.seed_graph.in_degrees()\n",
    "        self.out_degrees = self.seed_graph.out_degrees()\n",
    "        potential_max    = min(int(torch.max(self.in_degrees)),\n",
    "                               int(torch.max(self.out_degrees)),self.maximum_class_size)\n",
    "        if self.maximum_dimension > potential_max:\n",
    "            print(\"The given graph cannot have simplices of dimension\", self.maximum_dimension)\n",
    "            print(\"Changing \",self.maximum_dimension, \"to\", potential_max)\n",
    "            self.maximum_dimension = potential_max\n",
    "            \n",
    "    def _close_db(self):\n",
    "        self.connection.commit()\n",
    "        self.connection.close()\n",
    "        \n",
    "    def _connect_db(self):\n",
    "        self.connection = sqlite3.connect(self.database_name)\n",
    "        self.cursor = self.connection.cursor()\n",
    "        \n",
    "    def _view_db(self,table_name):\n",
    "        \"\"\"This function was created for easier visualization of the database\"\"\"\n",
    "        self._connect_db()\n",
    "        self.cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "        if table_name == 'edge_details':\n",
    "            columns_info = self.cursor.fetchall()\n",
    "            reduced_columns = columns_info[1:10] \n",
    "            columns = [column[1] for column in reduced_columns]\n",
    "            self.cursor.execute(f\"SELECT {', '.join(columns)} FROM {table_name}\")\n",
    "            rows = self.cursor.fetchall()\n",
    "        else:\n",
    "            self.cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "            columns = [column[1] for column in self.cursor.fetchall()]\n",
    "            self.cursor.execute(f\"SELECT * FROM {table_name}\")\n",
    "            rows = self.cursor.fetchall()\n",
    "        \n",
    "        table = tabulate(rows, headers=columns, tablefmt=\"pretty\")\n",
    "        print(table)\n",
    "        self._close_db()\n",
    "        \n",
    "        \n",
    "    def create_table(self):\n",
    "        \"\"\"This function creates the table, but does not intialize\n",
    "        data. Therefore, this function only needs to be run the first time. \"\"\"\n",
    "        self._connect_db()\n",
    "\n",
    "        self.cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS graph (\n",
    "                quotient_number INTEGER PRIMARY KEY,\n",
    "                number_of_nodes INTEGER,\n",
    "                number_of_edges INTEGER,\n",
    "                number_of_simplices INTEGER,\n",
    "                FOREIGN KEY (number_of_nodes) REFERENCES node_classes(node_class_id),\n",
    "                FOREIGN KEY (number_of_edges) REFERENCES edge_details(edge_id),\n",
    "                FOREIGN KEY (number_of_simplices) REFERENCES simplices(simplex_id)\n",
    "                                            )\n",
    "                            ''')\n",
    "        self.cursor.execute(f'''\n",
    "            CREATE TABLE IF NOT EXISTS node_classes (\n",
    "                node_class_id INTEGER PRIMARY KEY,\n",
    "                quotient_id INTEGER,\n",
    "                number_of_nodes INTEGER,\n",
    "                globe_id,\n",
    "                {', '.join(f'node_{i} INTEGER DEFAULT NULL' for i in range(0, self.maximum_class_size))}\n",
    "                                                    )\n",
    "                            ''')\n",
    "        self.cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS edge_details (\n",
    "                edge_id INTEGER PRIMARY KEY,\n",
    "                e_src INTEGER,\n",
    "                e_dst INTEGER,\n",
    "                edge_changed BOOLEAN,\n",
    "                to_contract BOOLEAN,\n",
    "                sampled BOOLEAN,\n",
    "                contracted BOOLEAN,\n",
    "                quotient_id INTEGER,\n",
    "                multiplicity INTEGER,\n",
    "                globe_id INTEGER,\n",
    "                number_of_edges INTEGER\n",
    "                                                    )\n",
    "                            ''')\n",
    "        self.cursor.execute(f'''\n",
    "            CREATE TABLE IF NOT EXISTS simplices (\n",
    "                simplex_id INTEGER PRIMARY KEY,\n",
    "                quotient_id INTEGER,\n",
    "                dimension INTEGER,\n",
    "                globe_id,\n",
    "                number_of_simplices INTEGER,\n",
    "                {', '.join(f'index_{i} INTEGER DEFAULT NULL' for i in range(0, self.maximum_class_size))}\n",
    "                                                    )\n",
    "                            ''')\n",
    "        self._close_db()\n",
    "        \n",
    "        \n",
    "    def initial_db_fill(self):\n",
    "        \"\"\"Fills in the database with the details from the (unquotiented) graph itself\n",
    "        i.e., before the quotienting process. \"\"\"\n",
    "        self._connect_db()\n",
    "        self.cursor.execute('''INSERT INTO graph \n",
    "                            (quotient_number, number_of_nodes, number_of_edges, \n",
    "                            number_of_simplices) VALUES\n",
    "                            (0, ?, ?, 0)\n",
    "                            ''', (len(self.seed_graph.nodes()), \n",
    "                                  len(self.seed_graph.edges()[0]))\n",
    "                           )\n",
    "        \n",
    "        for node in self.seed_graph.nodes():\n",
    "            picked_set = self._globes.get(int(node),{node})\n",
    "            picked_id  = self._all_sets_with_indices.get(id(picked_set),'X') \n",
    "            if picked_id == 'X':\n",
    "                globe_id = -1\n",
    "            else:\n",
    "                globe_id = picked_id[1]\n",
    "            self.cursor.execute('''INSERT INTO node_classes\n",
    "                                (node_class_id, node_0, quotient_id, \n",
    "                                number_of_nodes, globe_id) VALUES \n",
    "                                (?, ?, 0, ?, ?)\n",
    "                                ''', (int(node), int(node),  \n",
    "                                      len(self.seed_graph.nodes()),\n",
    "                                      globe_id))\n",
    "        for edge in self.all_edges_as_pairs:\n",
    "            if torch.any(torch.all(self.edges_to_collapse_as_pairs == edge, dim=1)):\n",
    "                picked_set = self._globes.get(int(edge[0]),{int(edge[0])})\n",
    "                picked_id  = self._all_sets_with_indices[id(picked_set)] \n",
    "                globe_id   = picked_id[1]\n",
    "\n",
    "                self.cursor.execute('''INSERT INTO edge_details\n",
    "                                    (edge_id, e_src, e_dst, edge_changed, \n",
    "                                    to_contract, quotient_id, multiplicity, sampled,\n",
    "                                    number_of_edges, contracted, globe_id) VALUES \n",
    "                                    (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                                    ''', (self.edge_index, int(edge[0]), int(edge[1]), \n",
    "                                      False, True, 0, 1, False, len(self.seed_graph.edges()[0]),\n",
    "                                          False, globe_id)\n",
    "                                   )\n",
    "            elif torch.any(torch.all(self.existing_loops == edge, dim=1)):\n",
    "                self.cursor.execute('''INSERT INTO edge_details\n",
    "                                    (edge_id, e_src, e_dst, edge_changed, \n",
    "                                    to_contract, quotient_id, multiplicity, sampled,\n",
    "                                    number_of_edges, contracted, globe_id) VALUES \n",
    "                                    (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                                    ''', (self.edge_index, int(edge[0]), int(edge[1]), \n",
    "                                      False, False, 0, 1, False, len(self.seed_graph.edges()[0]),\n",
    "                                          True, -1)\n",
    "                                   )\n",
    "\n",
    "            else:\n",
    "                self.cursor.execute('''INSERT INTO edge_details\n",
    "                                    (edge_id, e_src, e_dst, edge_changed, \n",
    "                                    to_contract, quotient_id, multiplicity, sampled,\n",
    "                                    number_of_edges, contracted, globe_id) VALUES \n",
    "                                    (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                                    ''', (self.edge_index, int(edge[0]), int(edge[1]), \n",
    "                                      False, False, 0, 1, False, len(self.seed_graph.edges()[0]),\n",
    "                                         False, -1)\n",
    "                                   )\n",
    "            self.edge_index = self.edge_index + 1\n",
    "        \n",
    "        self._close_db()\n",
    "        \n",
    "    def sampling(self):\n",
    "        \"\"\"Samples edges to collapse, keeps track of changes in db for edges remaining to collapse.\"\"\"\n",
    "        self._connect_db()\n",
    "        # This query returns edges that have not yet been contracted.\n",
    "        self.cursor.execute(f'''SELECT e_src, e_dst\n",
    "                            FROM edge_details \n",
    "                            WHERE to_contract = True AND sampled = False\n",
    "                            AND edge_changed = False\n",
    "                            AND contracted = False AND quotient_id = {self.quotient_number}\n",
    "                            ORDER BY RANDOM()\n",
    "                            LIMIT {math.ceil(self.ratio * len(self.edges_to_collapse_as_pairs))}\n",
    "                            ''')\n",
    "        \n",
    "        self.selected_edges = self.cursor.fetchall()\n",
    "        # If two edges collapsing result in a third edge to collapse, we need to find it.\n",
    "        self._equivalenceclasses = {element:partition \n",
    "                                    for partition in relation(self.selected_edges) \n",
    "                                    for element in partition}\n",
    "        # When an edge collapses, we assign a new node label. The following list keeps track of this information.\n",
    "        changed_nodes = list(self._equivalenceclasses.keys())\n",
    "        \"\"\"To update entries of sampled edges in db, we first find all\n",
    "        the unique classes constructed above.\"\"\"\n",
    "        unique_sets = set()\n",
    "        for value in self._equivalenceclasses.values():\n",
    "            unique_sets.add(frozenset(value))\n",
    "        selected_edges = []\n",
    "        \n",
    "        for equivalence_class in unique_sets:\n",
    "            \"\"\"updates the column entry `sampled' for edges that have been sampled and those\n",
    "            that naturally won't be available for future quotienting\"\"\"\n",
    "            self.cursor.execute('''UPDATE edge_details\n",
    "                                SET sampled = True\n",
    "                                WHERE e_src IN ({}) AND e_dst IN ({}) AND quotient_id = ?\n",
    "                                '''.format(','.join(['?']*len(equivalence_class)),\n",
    "                                           ','.join(['?']*len(equivalence_class))),\n",
    "                                list(equivalence_class) + list(equivalence_class) +\n",
    "                                [self.quotient_number]\n",
    "                               )\n",
    "            \n",
    "            self.cursor.execute('''SELECT e_src, e_dst\n",
    "                                FROM edge_details\n",
    "                                WHERE contracted = False AND\n",
    "                                globe_id IS NOT -1 AND\n",
    "                                e_src IN ({}) AND e_dst IN ({})\n",
    "                                AND quotient_id = ?\n",
    "                                '''.format(','.join(['?']*len(equivalence_class)), \n",
    "                                            ','.join(['?']*len(equivalence_class))),\n",
    "                                    list(equivalence_class) + list(equivalence_class) +\n",
    "                               [self.quotient_number]\n",
    "                               )\n",
    "            selected_edges = selected_edges + self.cursor.fetchall()\n",
    "        self.selected_edges = selected_edges\n",
    "\n",
    "        \"\"\"Find out edges to carry forward\"\"\"\n",
    "        self.cursor.execute(f'''SELECT e_src, e_dst\n",
    "                            FROM edge_details \n",
    "                            WHERE to_contract = True AND sampled = False \n",
    "                            AND edge_changed = False AND contracted = False\n",
    "                            AND quotient_id ={self.quotient_number}\n",
    "                            ''')\n",
    "        \n",
    "        \"\"\"These are the egdes we do  not collapse after sampling and considering transitive closure\"\"\"\n",
    "        self.edges_carry_fwd = self.cursor.fetchall()\n",
    "        \n",
    "        self.cursor.execute('''UPDATE edge_details\n",
    "                            SET edge_changed = True\n",
    "                            WHERE e_src IN ({}) AND e_dst IN ({});\n",
    "                            '''.format(','.join(['?']*len(changed_nodes)),\n",
    "                                       ','.join(['?']*len(changed_nodes))), \n",
    "                            changed_nodes + changed_nodes)\n",
    "        self._close_db()\n",
    "        \n",
    "    def make_quotient(self):\n",
    "        \"\"\"This section can be combined with the db fill function above\n",
    "        The only reason this is kept distinct is to keep the class modular\"\"\"\n",
    "        self.new_edges_added = list()\n",
    "        self.new_nodes_added = set()\n",
    "        \n",
    "        self._sets = {id(self._equivalenceclasses[key]):self._equivalenceclasses[key]\n",
    "                      for key in self._equivalenceclasses.keys()}\n",
    "        # Create mapping of class names\n",
    "        self._classesnamesmapping = dict()\n",
    "        \n",
    "        for setid in self._sets.keys():\n",
    "            self._classesnamesmapping[setid] = self.appendage_index\n",
    "            self.appendage_index = self.appendage_index + 1\n",
    "                    \n",
    "        for key, value in self._classesnamesmapping.items():\n",
    "            element_of_set = next(iter(self._sets[key]))\n",
    "            globe_associated = self._globes[element_of_set]\n",
    "            self._globes.update({value:globe_associated})\n",
    "                    \n",
    "        # Each set (node class) is assigned a new node label.\n",
    "        for edge in self.selected_edges:\n",
    "            nodeclass    = self._equivalenceclasses[edge[0]]\n",
    "            newnodelabel = self._classesnamesmapping[id(nodeclass)]\n",
    "            self.new_edges_added = self.new_edges_added + [(newnodelabel,newnodelabel)]\n",
    "            self.new_nodes_added = self.new_nodes_added.union({newnodelabel})\n",
    "\n",
    "        # Since the node labels are changed, the edges that still need to be contracted will\n",
    "        # have their src and dst changed. To keep track of these un-contracted edges, we put them in the \n",
    "        # edges_carry_fwd variable\n",
    "        for edge in self.edges_carry_fwd:\n",
    "            srcnodeclass    = self._equivalenceclasses.get(edge[0], edge[0])\n",
    "            srcnewnodelabel = self._classesnamesmapping.get(id(srcnodeclass),edge[0])\n",
    "            dstnodeclass    = self._equivalenceclasses.get(edge[1], edge[1])\n",
    "            dstnewnodelabel = self._classesnamesmapping.get(id(dstnodeclass),edge[1])\n",
    "            self.new_edges_added = self.new_edges_added + [(srcnewnodelabel,dstnewnodelabel)]\n",
    "            self.new_nodes_added = self.new_nodes_added.union({srcnewnodelabel,dstnewnodelabel})\n",
    "            \n",
    "        print(\"Created a quotient\")\n",
    "        \n",
    "        # Remove variables to save space\n",
    "        self.edges_carry_fwd = None\n",
    "        self.selected_edges  = None\n",
    "        \n",
    "        self.quotient_number = self.quotient_number + 1\n",
    "        \n",
    "    def db_fill(self):\n",
    "        \"\"\"This function saves the details of a quotiented graph in the database.\n",
    "        Therefore, this function should be called immediately after the quotient is made.\n",
    "        All the edges of the graph are added, and are given different IDs, even if the edges\n",
    "        are already present in a previous quotient. However, we have different collections\n",
    "        here to ensure that the edges that have been changed are discarded from the edges\n",
    "        that need to be sampled. To this end, we add three new columns viz. to_contract, sampled\n",
    "        and contracted.\"\"\"\n",
    "        # To count the multiplicities of the edges\n",
    "        edge_counter        = collections.Counter(self.new_edges_added)\n",
    "        number_of_edges     = len(edge_counter)\n",
    "        number_of_nodes     = len(self.new_nodes_added)\n",
    "        \n",
    "        self._connect_db()\n",
    "        self.cursor.execute('''INSERT INTO graph \n",
    "                            (quotient_number, number_of_nodes, number_of_edges, \n",
    "                            number_of_simplices) VALUES\n",
    "                            (?, ?, ?, 0)\n",
    "                            ''', (self.quotient_number, \n",
    "                                  number_of_nodes,\n",
    "                                  number_of_edges)\n",
    "                           )\n",
    "        \n",
    "        edge_details_data = list()\n",
    "        for edge, count in edge_counter.items():\n",
    "            picked_set = self._globes[int(edge[0])]\n",
    "            picked_id = self._all_sets_with_indices[id(picked_set)]\n",
    "            globe_id = picked_id[1]\n",
    "            values = (self.edge_index, int(edge[0]), int(edge[1]),\n",
    "                      False, True, self.quotient_number, count,\n",
    "                      edge[0] == edge[1], number_of_edges,\n",
    "                      edge[0] == edge[1], globe_id)\n",
    "            edge_details_data.append(values)\n",
    "            self.edge_index += 1\n",
    "            \n",
    "        query = '''INSERT INTO edge_details \n",
    "                    (edge_id, e_src, e_dst, edge_changed, \n",
    "                    to_contract, quotient_id, multiplicity, sampled,\n",
    "                    number_of_edges, contracted, globe_id) VALUES \n",
    "                    (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'''\n",
    "\n",
    "        self.cursor.executemany(query, edge_details_data)\n",
    "            \n",
    "        # Removing variable to save space\n",
    "        self.new_edges_added = None\n",
    "        edge_details_data = None\n",
    "        \n",
    "        node_classes_data = []\n",
    "\n",
    "        for setid, classlabel in self._classesnamesmapping.items():\n",
    "            node_data = self._sets[setid]\n",
    "            node = next(iter(node_data))\n",
    "            picked_set = self._globes.get(int(node),{node})\n",
    "            picked_id  = self._all_sets_with_indices.get(id(picked_set),'X')\n",
    "            if picked_id == 'X':\n",
    "                globe_id = -1\n",
    "            else:\n",
    "                globe_id = picked_id[1]\n",
    "            data_row = [globe_id, classlabel, self.quotient_number, number_of_nodes] + list(node_data) + [None] * (self.maximum_class_size - len(node_data))\n",
    "            node_classes_data.append(data_row)\n",
    "            \n",
    "        columns = ['globe_id', 'node_class_id', 'quotient_id', 'number_of_nodes']\n",
    "        columns = columns + [f'node_{i}' for i in range(0, self.maximum_class_size)]\n",
    "        placeholders = ', '.join(columns)\n",
    "        query = f'''INSERT INTO node_classes ({placeholders})\n",
    "                    VALUES ({', '.join(['?'] * len(columns))})\n",
    "                    '''\n",
    "        self.cursor.executemany(query, node_classes_data)\n",
    "        self._close_db()\n",
    "        \n",
    "                \n",
    "    def empty_table(self, table_name):\n",
    "        \"\"\"Made this function to empty database without deleting database. \n",
    "        Helpful for debugging\"\"\"\n",
    "        self._connect_db()\n",
    "        self.cursor.execute(f\"DELETE FROM {table_name}\")\n",
    "        self._close_db()\n",
    "        \n",
    "    def create_towers(self):\n",
    "        self.initial_db_fill()\n",
    "        print(\"DB initiliazed. Now creating quotients\")\n",
    "        for index in tqdm(range(self.bottom_level+1)):\n",
    "            self.sampling()\n",
    "            if len(self.selected_edges) == 0:\n",
    "                print(\"The graph cannot be quotiented further.\")\n",
    "                print(\"Changing bottom level to\",self.quotient_number)\n",
    "                self.bottom_level = self.quotient_number                \n",
    "                break\n",
    "            self.make_quotient()\n",
    "            self.db_fill()\n",
    "        print(\"Initial DB filled.\")\n",
    "            \n",
    "    def extract_from_db(self,quotient_number, globe_number):\n",
    "        \"\"\"This function extracts information about the graphs upstairs and downstairs, \n",
    "        given the quotient number and globe number. In addition, it also picks up simplices \n",
    "        from a graph below it in the hierarchy, and computes the lift of each simplex.\n",
    "        These lifts are fed to the simplicial search function Unpacker\"\"\"\n",
    "        \n",
    "        domain_graph = dgl.heterograph({('node', 'to', 'node'): ([], [])})\n",
    "                \n",
    "        self._connect_db()\n",
    "        # The constraint contracted = False ensures that we don't pick up loops.\n",
    "        self.cursor.execute(f'''SELECT e_src, e_dst\n",
    "                            FROM edge_details\n",
    "                            WHERE quotient_id = {quotient_number-1} \n",
    "                            AND contracted = False\n",
    "                            AND globe_id = {globe_number}\n",
    "                            ''')\n",
    "        domain_graph_edges = self.cursor.fetchall()\n",
    "        \n",
    "        self.cursor.execute(f'''SELECT * FROM simplices\n",
    "                            WHERE quotient_id = {quotient_number}\n",
    "                            AND globe_id = {globe_number}\n",
    "                            ''')\n",
    "        simplex_details = self.cursor.fetchall()\n",
    "        self.cursor.execute(f'''SELECT simplex_id FROM simplices\n",
    "                            ''')\n",
    "        all_simplex_ids = self.cursor.fetchall()\n",
    "        self.cursor.execute(f'''SELECT e_src, e_dst\n",
    "                            FROM edge_details\n",
    "                            WHERE quotient_id = {quotient_number}\n",
    "                            AND globe_id = {globe_number}\n",
    "                            ''')\n",
    "        range_graph_edges_db = self.cursor.fetchall()\n",
    "        self._close_db()\n",
    "        nodes_to_lift = set()\n",
    "        simplices_to_lift = dict()\n",
    "        if len(domain_graph_edges) == 0:\n",
    "            return ('empty_graph',)\n",
    "        \n",
    "        deg_edges = list()\n",
    "        range_graph_edges=list()\n",
    "        for row in range_graph_edges_db:\n",
    "            e_src        = row[0]\n",
    "            e_dst        = row[1]\n",
    "            nodes_to_lift = nodes_to_lift.union({e_src, e_dst})\n",
    "            if e_src == e_dst:\n",
    "                deg_edges = deg_edges + [[e_src, e_dst]]\n",
    "            else:\n",
    "                range_graph_edges.append([e_src,e_dst])\n",
    "        \n",
    "        nodes_to_lift = list(nodes_to_lift)\n",
    "        domain_graph_nodes = set()\n",
    "                \n",
    "        for src, dst in domain_graph_edges:\n",
    "            domain_graph.add_edges(src,dst)\n",
    "            domain_graph_nodes=domain_graph_nodes.union({src,dst})\n",
    "            \n",
    "        prev_nodes = list()\n",
    "        dimensions = list()\n",
    "\n",
    "        for row in simplex_details:\n",
    "            simplex_id, dimension = row[0], row[2]\n",
    "            index_values = row[5:]\n",
    "            index_values = list(value for value in index_values if value is not None)\n",
    "            simplices_to_lift[(dimension, simplex_id)] = index_values\n",
    "            if dimension == 0:\n",
    "                prev_nodes = prev_nodes + [row[4]]\n",
    "            dimensions = dimensions + [dimension]\n",
    "        simplex_index = max(all_simplex_ids, key=lambda x: x[0], default=(0,))[0] + 1\n",
    "        \n",
    "        \"\"\"Node IDs are kept the same as their labels. Since a node may be present in different quotient, \n",
    "        the nodes for each quotient are not present in the database. This information is extracted when\n",
    "        edges are constructed..\"\"\"\n",
    "        \n",
    "        \"\"\"Construct a dictionary of pre-images of the quotient ----> quotient+1 map on nodes. That is,\n",
    "        creates a mapping of node labels to their equivalence classes.\"\"\"\n",
    "\n",
    "        columns = ['node_class_id'] + ['globe_id'] +[f'node_{i}' for i in range(0, self.maximum_class_size)]\n",
    "        column_names = ', '.join(columns)\n",
    "        in_placeholders = ', '.join(['?' for _ in nodes_to_lift])\n",
    "        self._connect_db()\n",
    "        self.cursor.execute(f'''SELECT {column_names}\n",
    "                            FROM node_classes\n",
    "                            WHERE node_class_id IN ({in_placeholders})\n",
    "                            ''', tuple(nodes_to_lift))\n",
    "        node_mapping_db = self.cursor.fetchall()\n",
    "        \n",
    "        self._close_db()\n",
    "        \n",
    "        node_mapping  = dict()\n",
    "        \n",
    "        for row in node_mapping_db:\n",
    "            key      = row[0]\n",
    "            globe_id = row[1] \n",
    "            values   = row[2:]\n",
    "            values   = list(value for value in values if value is not None)\n",
    "            node_mapping.update({key: values})\n",
    "            \n",
    "        for node in list(domain_graph_nodes):\n",
    "            node_mapping[node] = [node]\n",
    "            \n",
    "        return (domain_graph, node_mapping, range_graph_edges, \n",
    "                deg_edges, simplices_to_lift, simplex_index,domain_graph_edges)\n",
    "        \n",
    "    def simplices_of_quotient(self,quotient_number):\n",
    "        \n",
    "        for globe_id in range(self.max_globe_index+1):\n",
    "            simplices = dict()\n",
    "            returns = self.extract_from_db(quotient_number, globe_id)\n",
    "            if returns[0] == 'empty_graph':\n",
    "                # We have an empty graph, so we can move on to the next iteration\n",
    "                continue\n",
    "            simplex_finder = Unpacker(domain_graph=returns[0],node_mapping=returns[1],range_graph_edges=returns[2],\n",
    "                                      deg_edges=returns[3],quotiented_simplices=returns[4],\n",
    "                                      simplex_max_index=returns[5],globe_number=globe_id,domain_graph_edges=returns[6])\n",
    "            if simplex_finder.local_max_dim == 1:\n",
    "                # There's no simplices to be found, so we can move on to the next iteration\n",
    "                continue\n",
    "            simplex_finder.inductive_connecting()\n",
    "            local_simplices = simplex_finder.lifted_simplices\n",
    "            simplices.update(local_simplices)\n",
    "            number_of_simplices = len(simplices.values())\n",
    "            if number_of_simplices == 0:\n",
    "                # No simplices have been found, so we can move on to the next iteration\n",
    "                continue\n",
    "            \n",
    "            # Otherwise, we add the found simplices to the database\n",
    "            \n",
    "            data_to_insert = []\n",
    "            for key, element in simplices.items():\n",
    "                dimension  = key[0]\n",
    "                simplex_id = key[1]\n",
    "                globe_id   = key[2]\n",
    "\n",
    "                data_row = [dimension, simplex_id, quotient_number-1, number_of_simplices,\n",
    "                            globe_id] + element + [None] * (self.maximum_class_size - len(element))\n",
    "                data_to_insert.append(data_row)\n",
    "            columns = ['dimension', 'simplex_id', 'quotient_id', 'number_of_simplices']\n",
    "            columns = columns + ['globe_id'] +[f'index_{i}' for i in range(self.maximum_class_size)]\n",
    "            placeholders = ', '.join(columns)\n",
    "            query = f'''INSERT INTO simplices ({placeholders})\n",
    "                    VALUES ({', '.join(['?'] * len(columns))})\n",
    "                    '''\n",
    "            self._connect_db()\n",
    "            self.cursor.executemany(query, data_to_insert)\n",
    "            self._close_db()\n",
    "        \n",
    "    def simplicial_search(self):        \n",
    "        print(\"Searching for simplices..\")\n",
    "        starting = self.bottom_level\n",
    "        for q_id in tqdm(range(starting, 0, -1)):\n",
    "            print(\"Search on-going in quotient number\",q_id)\n",
    "            self.simplices_of_quotient(q_id)\n",
    "            \n",
    "            \n",
    "\"\"\"found from https://stackoverflow.com/questions/42069187/\n",
    "create-a-list-of-unique-numbers-by-applying-transitive-closure\"\"\"\n",
    "def relation(array):\n",
    "\n",
    "    mapping = {}\n",
    "\n",
    "    def parent(u):\n",
    "        if mapping[u] == u:\n",
    "            return u\n",
    "        mapping[u] = parent(mapping[u])\n",
    "        return mapping[u]\n",
    "\n",
    "    for u, v in array:\n",
    "        u = int(u)\n",
    "        v = int(v)\n",
    "        if u not in mapping:\n",
    "            mapping[u] = u\n",
    "        if v not in mapping:\n",
    "            mapping[v] = v\n",
    "        mapping[parent(u)] = parent(v)\n",
    "\n",
    "    results = collections.defaultdict(set)\n",
    "    \n",
    "\n",
    "    for u in mapping.keys():\n",
    "        results[parent(u)].add(u)\n",
    "\n",
    "        \n",
    "    return [x for x in results.values()]\n",
    "\n",
    "            \n",
    "def find_common_tensors(tensor_A,tensor_B):\n",
    "    equal_pairs = torch.all(tensor_A[:, None, :] == tensor_B[None, :, :], dim=2)\n",
    "    common_pair_indices = torch.nonzero(equal_pairs, as_tuple=False)\n",
    "    return tensor_A[common_pair_indices[:, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dbc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplexCreator():\n",
    "    \"\"\"Create standard simplex\"\"\"\n",
    "    def __init__(self, dimension):\n",
    "        self.input_dimension = dimension\n",
    "        self.src=list()\n",
    "        self.dst=list()\n",
    "        for i in range(self.input_dimension+1):\n",
    "            for j in range(self.input_dimension+1):\n",
    "                if (i < j):\n",
    "                    self.src = self.src + [i]\n",
    "                    self.dst = self.dst + [j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ae0df",
   "metadata": {},
   "source": [
    "#### Code testing\n",
    "When running the graphs for the first time, you will need to run the create_table() module to set the database for this particular graph. Once that it done, ensure that you clear off the database using the empty_table() modules. The arguments have been fed already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f91ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_5 = dgl.heterograph({('paper', 'cites', 'paper'): (SimplexCreator(dimension=5).src, SimplexCreator(dimension=5).dst)})\n",
    "filepath = 'K_5'\n",
    "db = 'K_5.db'\n",
    "K_5_preprocessing = graph_towers(filepath,graph=K_5, database_name=db, ratio=0.01,bottom_level = 10, max_dimension = 23)\n",
    "K_5_preprocessing.create_table()\n",
    "#K_5_preprocessing.empty_table('edge_details')\n",
    "#K_5_preprocessing.empty_table('graph')\n",
    "#K_5_preprocessing.empty_table('node_classes')\n",
    "#K_5_preprocessing.empty_table('simplices')\n",
    "#K_5_preprocessing.create_towers()\n",
    "#K_5_preprocessing.simplicial_search()\n",
    "cProfile.run('K_5_preprocessing.create_towers()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9166e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run('K_5_preprocessing.simplicial_search()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0bf0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the resulting databases after the search\n",
    "K_5_preprocessing._view_db('graph')\n",
    "K_5_preprocessing._view_db('node_classes')\n",
    "K_5_preprocessing._view_db('edge_details')\n",
    "K_5_preprocessing._view_db('simplices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69559856",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = [0,0,0,1,1,2] + [1] + [4,4,4,5,5,6] \n",
    "dst = [1,2,3,2,3,3] + [4] + [5,6,7,6,7,7] \n",
    "twosimplices = dgl.heterograph({('paper', 'cites', 'paper'): (src, dst)})\n",
    "filepath = 'twosimplices'\n",
    "db2 = 'twosimplices.db'\n",
    "twosimplices_preprocessing = graph_towers(filepath,database_name = db2, graph=twosimplices,ratio=0.01,bottom_level = 20, max_dimension = 20)\n",
    "twosimplices_preprocessing.create_table()\n",
    "#twosimplices_preprocessing.empty_table('edge_details')\n",
    "#twosimplices_preprocessing.empty_table('graph')\n",
    "#twosimplices_preprocessing.empty_table('node_classes')\n",
    "#twosimplices_preprocessing.empty_table('simplices')\n",
    "cProfile.run('twosimplices_preprocessing.create_towers()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf52da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run('twosimplices_preprocessing.simplicial_search()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df739a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "twosimplices_preprocessing._view_db('graph')\n",
    "twosimplices_preprocessing._view_db('node_classes')\n",
    "twosimplices_preprocessing._view_db('edge_details')\n",
    "twosimplices_preprocessing._view_db('simplices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc790bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_j = [0,0,1,1,1,5,2,2,3] + [5] + [6,6 ,7,15,15,8] + [7]  + [13,13,10,13,10,11] + [0,14]\n",
    "dst_j = [1,2,2,3,5,3,3,4,4] + [6] + [7,15,15,8,9,9]  + [13] + [10,11,11,12,12,12] + [14,10]\n",
    "jumbo = dgl.heterograph({('paper', 'cites', 'paper'): (src_j, dst_j)})\n",
    "filepath3 = 'jumbo'\n",
    "db3 = 'jumbo.db'\n",
    "jumbo_preprocessing = graph_towers(filepath3,database_name = db3, graph=jumbo,ratio=0.01,bottom_level = 20, max_dimension = 20)\n",
    "jumbo_preprocessing.create_table()\n",
    "#jumbo_preprocessing.empty_table('edge_details')\n",
    "#jumbo_preprocessing.empty_table('graph')\n",
    "#jumbo_preprocessing.empty_table('node_classes')\n",
    "#jumbo_preprocessing.empty_table('simplices')\n",
    "jumbo_preprocessing.create_towers()\n",
    "jumbo_preprocessing.simplicial_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4890a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "jumbo_preprocessing._view_db('graph')\n",
    "jumbo_preprocessing._view_db('node_classes')\n",
    "jumbo_preprocessing._view_db('edge_details')\n",
    "jumbo_preprocessing._view_db('simplices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb5a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_5_simplices_src = [0,0,0,0,0,1,1,1,1,2,2,2,3,3,4] + [3] + [6,6,6,6, 6, 7,7,7, 7, 8, 8, 8, 9, 9,10] + [11,12] + [13,13,13,13,13,14,14,14,14,15,15,15,16,16,17]\n",
    "multiple_5_simplices_dst = [1,2,3,4,5,2,3,4,5,3,4,5,4,5,5] + [6] + [7,8,9,10,11,8,9,10,11,9,10,11,10,11,11] + [12,13] + [14,15,16,17,18,15,16,17,18,16,17,18,17,18,18]\n",
    "multiple_5_simplices = dgl.heterograph({('paper', 'cites', 'paper'): (multiple_5_simplices_src, multiple_5_simplices_dst)})\n",
    "filepath = 'multiple_5_simplices'\n",
    "db4 = 'multiple_5_simplices.db'\n",
    "mulitpl5_preprocessing = graph_towers(filepath,database_name = db4, graph=multiple_5_simplices,ratio=0.01,bottom_level = 20, max_dimension = 20)\n",
    "mulitpl5_preprocessing.create_table()\n",
    "#mulitpl5_preprocessing.empty_table('edge_details')\n",
    "#mulitpl5_preprocessing.empty_table('graph')\n",
    "#mulitpl5_preprocessing.empty_table('node_classes')\n",
    "#mulitpl5_preprocessing.empty_table('simplices')\n",
    "cProfile.run('mulitpl5_preprocessing.create_towers()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b53321",
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run('mulitpl5_preprocessing.simplicial_search()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14efe77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mulitpl5_preprocessing._view_db('graph')\n",
    "mulitpl5_preprocessing._view_db('node_classes')\n",
    "mulitpl5_preprocessing._view_db('edge_details')\n",
    "mulitpl5_preprocessing._view_db('simplices')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
